## Урок 3. Лекция. Механизмы контрольных групп
### План урока
1. cgroups – появление механизма процесс модификации
2. Архитектура и составляющие механизма
3. Примеры управления группами
4. Недостатки cgroups

### Вступление
Для полноценного запуска контейнеризированного приложения недостаточно лишь изоляции ресурсов. В случае запуска приложения в изолированном окружении, нужно быть уверенным, что приложение получит достаточное количество ресурсов, что приложение будет потреблять только необходимые ресурсы и ничего более. Это необходимо для сохранения стабильной работы как самого приложения, так и хостовой системы в целом.

Предположим, что у нас есть сайт, который состоит из визуальной части, то есть web-интерфейса и базы данных. У каждого приложения есть свои требования к системе:
программный и аппаратный. Программные требования мы пока опустим, а вот аппаратные обсудим.

Предположим, что для корректной работы сайта необходим двухъядерный процессор с тактовой частотой 1 Гц и минимум 1 Гб ОЗУ. Если сайт будет работать на голом железе - никаких проблем. Берем простой компьютер и настраиваем. В случае же, если мы работаем с контейнерами, необходима не только изоляция ресурсов, но и гарантированная выдача аппаратных ресурсов. Просто запустив приложение изолированно и, параллельно запуская другие, может случиться так, что нашим компонентам сайта попросту не хватит аппаратных ресурсов, что приведет к замедлению работы в лучшем случае, в худшем - к полной неработоспособности нашего сайта.

Для решения этой задачи в ядре ОС Linux уже встроен специальный механизм: механизм контрольных групп (cgroups (control groups)).

### Историческая справка
Изначальное назначение утилиты было довольно простым: усовершенствование имеющегося механизма cpuset, который отвечал за распределение процессорного времени и оперативной памяти между всеми запущенными процессами и задачами. Однако, со временем проект перерос себя и был переориентирован.

Данная технология начала встраиваться в официальные версии ядра несколько позже (в 2008 году), начиная с версии 2.6.24, когда была доработана и протестирована. С момента добавления в ядро, разработка значительно ускорилась и было добавлено много дополнительных возможностей, а механизм начал использоваться в технологии инициализации systemd, являясь при этом ключевым элементом в реализации системы виртуализации на уровне операционной системы LXC.

### LXC-подсистема контейнеризации
Данная подсистема позволяет запускать несколько изолированных друг от друга экземпляров ОС Linux на одном узле. Важно отметить, что данная система не использует технологию виртуализации, то есть не создает виртуальных машин. Система создает виртуальное окружение с собственным пространством процессов и сетевым стеком.

### Возможности и использование
Основной целью механизма является предоставление единого программного интерфейса к ряду средств управления процессами: начиная с контроля просто единичного управления процессом, заканчивая полной виртуализацией на уровне системы (пример - LXC).  
Механизм предоставляет ряд возможностей:
- Ограничение ресурсов (как виртуальных, так и физических) - использование памяти и процессорного времени.
- Приоритизация. Разным группам приложений можно выделить различное количество ресурсов процессора и, например, пропускной способности ввода-вывода (дисковой подсистемы).
- Регистрация затрат тех или иных ресурсов приложением либо группой приложений.
- Изоляция. Предполагается, что приложения используют распределенное пространство имен таким образом, что процессы одной группы недоступны другой. Та же участь касается и сетевой инфраструктуры и прочих ресурсов.
- Управление. Возможность перезагрузки процессов, создания дополнительных квот и ограничений.

Механизм состоит из двух главных частей: ядра (cgroup core) и подсистем. Список подсистем зависит от версии ядра. Основные компоненты следующие:
- blkio — подсистема устанавливает квоты на чтение и запись с блочных устройств.
- cpuacct — формирует отчеты об использовании ресурсов процессора.
- cpu — предоставляет доступ процессам в рамках контрольной группы к ресурсам процессорной подсистемы.
- cpuset — распределяет задачи в рамках контрольной группы между имеющимися процессорными ядрами.
- devices — предоставляет доступ или же, наоборот, блокирует доступ к устройствам.
- freezer — приостанавливает и возобновляет выполнение задач в рамках контрольной группы.
- memory — занимается выделением памяти для групп процессов.
- net_cls — помечает сетевые пакеты специальным тэгом, который в дальнейшем позволяет идентифицировать пакеты, порождаемые определённой задачей в рамках контрольной группы.
- netprio — используется для динамической установки приоритетов по трафику.
- ns - используется для группировки процессов в отдельное пространство имен, где процессы могут взаимодействовать между собой и при этом будут изолированы от внешних процессов.
- pids — используется для ограничения количества процессов в рамках контрольной группы.
- unified — автоматически монтирует файловую систему в каталог /sys/fs/cgroup/unified при запуске системы.

Подсистемы представляют собой модули ядра, каждый из которых отвечает за выделение системных ресурсов контрольным группам. Разумеется, можно по отдельности запрограммировать подсистемы с целью создания индивидуального подхода к управлению группами процессов. Интерфейс программирования задокументирован в файле: https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt

Объекты состояния могут содержать параметры подсистем для каждой контрольной группы и представляются в виде псевдофайлов в виртуальной файловой системе.

Каждая подсистема представляет собой директорию с набором управляющих файлов, в которых и прописываются все настройки.

Помимо специализированных файлов, каждая директория содержит в себе набор управляющих файлов:
- cgroup.clone_children — позволяет передавать дочерним контрольным группам свойства родительских.
- tasks — содержит список PID всех процессов, включённых в контрольные группы.
- cgroup.procs — содержит список TGID (Thread Group Id) групп процессов, включённых в контрольные группы.
- cgroup.event_control — позволяет отправлять уведомления в случае изменения статуса контрольной группы.
- release_agent — содержится команда, которая будет выполнена, если включена опция notify_on_release. Может использоваться, например, для автоматического удаления пустых контрольных групп.
- notify_on_release — содержит булеву переменную (0 или 1), включающую (или, наоборот, отключающую), выполнение команду, указанной в release_agent.

**Псевдофайл** - файл, который не представляет из себя файл в базовой файловой системе на диске. Это файлы, которые автоматически создаются для представления какого-либо другого объекта в виде файла с целью возможности взаимодействия с ним. Простой пример /dev/sda.

### blkio (block I/O)
blkio - это подсистема управления процедурами ввода/вывода блочных устройств. Для ограничения доступа приложению или процессу записываются значения в псевдофайлы. Подсистема содержит огромное количество параметров. Предлагается рассмотреть наиболее важные:
- blkio.weight - позволяет определить относительный вес (в значениях от 100 до 1000) ввода-вывода контрольной группы. В данном случае, чем больше значение, тем больше ресурсов получит приложение или процесс. Аналогию можно провести довольно простую: при значении 100 приложение получит возможность производить 100 операций чтения/записи в секунду. Можно определить дополнительное значение для отдельных устройств в отдельный псевдофайл: blkio.weight_device. Пример определения параметра в псевдофайл выглядит следующим образом: `echo 200 > blkio.weight`
- blkio.weight_device - определяет относительный вес для конкретного устройства, которое доступно в файловой системе. Этот параметр позволяет переопределить общее значение blkio.weight. Переопределение выглядит следующим образом: `echo 8:0 200 > blkio.weight_device`  
Вывод такой в связи с тем, что устройство /dev/sda соответствует в списке устройств номеру 8:0. Проверить это можно с помощью команды `lsblk`:
```bash
lsblk
NAME MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda    8:0    0 389.8M  1 disk
sdb    8:16   0     1G  0 disk [SWAP]
sdc    8:32   0     1T  0 disk /mnt/wslg/distro
```
Как можно видеть, значения, вводимые нами, совпадают со значениями, выводимыми системой.

### cpu
Эта подсистема отвечает за управление доступом контрольных групп к процессорам системы. Доступ регламентируется параметрами, которые так же, как и в предыдущем случае, записываются в псевдофайлы. Принцип такой же: один параметр - один псевдофайл. Рассмотрим наиболее значимые:
- cpu.shares - целочисленный параметр, которые определяет относительную величину доступного процессорного времени. Например: есть две контрольные группы. У одной из них это значение равно единице, у второй - 2. Это значит, что процессы из второй контрольной группы будут получать вдвое больше процессорного времени при выполнении той или иной задачи.
- cpu_rt_runtime_us - этим параметром определяется максимальный период времени (в микросекундах), в течение которого задания того или иного процесса могут использовать процессорные ресурсы. Данный параметр очень важен, так как это ограничение позволяет предотвратить монопольное использование ресурсов одной подгруппой.
- cpu._rt_period_us - здесь же определяется интерфал, по истечении которого приложения из контрольной группы получат доступ к процессорным ресурсам.

Пример довольно прост: если нам необходимо, чтобы процессы из группы имели доступ к процессору длиной в 5 секунд каждые 10 секунд, необходимо задать следующие значения:
```
cpu.rt_runtime_us 4000000
cpu.rt_period_us 10000000
```

### cpuacct
Данная подсистема создает отчеты о занятости ресурсов процессора. Всего имеется три вида отчетов:
- cpuacct.stat - этот отчет возвращает число циклов процессора (величина измерения - USER_HZ), которые были затрачены на обработку заданий контрольной группы. Учитывается пользовательский и системный режим.
- cpuacct.usage - возвращает суммарное время (единица измерения - наносекунды), в течение которого ресурсы процессора были заняты обработкой заданий контрольной группы.
- cpuacct.usage_percpu - как и прошлый отчет, возвращает время, в течение которого ресурсы были заняты обработкой всех заданий контрольной группы, но попроцессорно.

### cpuset
Подсистема, отвечающая за выделение ресурсов процессора контрольным группам. Также, как и ранее, каждый параметр хранится в отдельном псевдофайле. Например:
- cpuset.cpus - параметр, определяющий количество процессоров, к которым могут обращаться процессы в контрольной группе. Записывать в файл можно как диапазон используемых процессоров (0-2), так и какие-то отдельные через запятую. Пример: если в файле записано какое-либо число (для простоты - 0), то приложение будет иметь доступ только к этому процессору. Остальные не будут задействованы для этой задачи. Важно отметить, что этот же процессор может быть задействован для решения и других задач. Если мы хотим, чтобы он был задействован только для решения нашей задачи, используйте следующий параметр.
- cpuset.cpu_exclusive - этим параметром можно задать, возможность совместного использования процессоров, которые были перечислены ранее.

### devices
Эта подсистема отвечает за управление доступом к устройствам. Она включена в ОС Linux относительно недавно в отличие от ранее рассмотренных и имеет наименьшее число возможных параметров:
- devices.allow - в этот псевдофайл записываются устройства, к которым
разрешен доступ в рамках контрольной группы. Каждая запись содержит по
четыре поля: тип устройства, старший номер, младший номер, режим
доступа. На первый взгляд кажется, что все сложно, но нет. Давайте
рассмотрим каждое поле с примерами:
  - тип устройства. Здесь могут быть следующие значения:
    - a - применяется ко всем символьным и блочным устройствам
    - b - блочное устройство
    - c - символьное устройство (ссылка на устройство, на файл)
  - старший и младший номера - они разделяются двоеточием и идентифицируют конечное устройство в ОС Linux. Например, значение 8:1 обозначает следующее:
    - 8 - старший номер, обозначающий диски SCSi
    - 1 - младший номер, обозначающий первый раздел на первом диске  
    Явно этот пример мы уже видели ранее, но сейчас можно освежить память:
    ```bash
    lsblk
    NAME MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
    sda    8:0    0 389.8M  1 disk
    sdb    8:16   0     1G  0 disk [SWAP]
    sdc    8:32   0     1T  0 disk /mnt/wslg/distro
    ```
  - режим доступа - определяется доступ к устройству, которое будет иметь контрольная группа, Доступны следующие варианты:
    - r - доступ разрешен только на чтение
    - w - доступ разрешен на чтение и запись
    - m - разрешение доступа на создание файлов, если они не существуют
- devices.deny - полная противоположность предыдущей опции. Запрещает доступ к устройствам. Формат записи идентичный предыдущему.
- devices.list - в этом псевдофайле будут устройства, для которых было настроено управление доступом.

### freezer
Из названия может быть понятно, что эта подсистема отвечает за остановку и возобновление заданий контрольной группы. У нее есть всего один псведофайл:
- freezer.state - статус подсистемы. Она имеет несколько допустимых значений:
  - frozen - задания приостановлены
  - freezing - система в стадии приостановки задач
  - thawed - возобновление работы заданий в группе

Важное замечание: в файл можно записать лишь два значения: frozen и thawed. Значение freezing нельзя записать и его система сама записывает в файл. Это состояние - переходное для процесса.

### memory
Подсистема создает отчеты об использовании ресурсов оперативной памяти. Также позволяет наложить ограничения с помощью ряда параметров. Рассмотрим несколько:
- memory.stat - возвращает статистику использования памяти.
- memory.usage_in_bytes - отображается суммарный размер памяти, которая занята процессами контрольной группы.
- memory.max_usage_in_bytes - максимальный размер памяти, доступный процессам контрольной группы.
- memory.limit_in_bytes - здесь задается максимальный размер памяти, включая файл подкачки.
- memory.failcnt - этот файл является счетчиком случаев достижения лимита, который задается в memory.limit_in_bytes.

### net_cls
Эта подсистема присваивает сетевым пакетам идентификатор, который помогает контроллеру идентифицировать пакеты, поступающие из контрольной группы. Также можно изменить настройки так, чтобы пакетам из различных групп назначался разный приоритет.

Единственный параметр net_cls.classid представляет из себя шестнадцатиричное значение, которое идентифицирует обработчик трафика.

### Практическое знакомство: проверка теории
Создаем новую директорию в пространстве имен
```bash
# Открываем bash в режиме суперпользователя
sudo bash
# Создаем новую cgroup
mkdir /sys/fs/cgroup/cpuset/testgroup1
mkdir: cannot create directory ‘/sys/fs/cgroup/cpuset/testgroup1’: Read-only file system
# как видим система смонтирована в режиме чтения, проверяем это
# Смотрим список смонтированных систем и проверяем свободное место
df -h
Filesystem      Size  Used Avail Use% Mounted on
none            1.9G  4.0K  1.9G   1% /mnt/wsl
none            119G  103G   16G  87% /usr/lib/wsl/drivers
/dev/sdc       1007G  1.8G  954G   1% /
none            1.9G   84K  1.9G   1% /mnt/wslg
none            1.9G     0  1.9G   0% /usr/lib/wsl/lib
rootfs          1.9G  2.1M  1.9G   1% /init
none            1.9G     0  1.9G   0% /dev
none            1.9G  440K  1.9G   1% /run
none            1.9G     0  1.9G   0% /run/lock
none            1.9G     0  1.9G   0% /run/shm
tmpfs           1.9G     0  1.9G   0% /sys/fs/cgroup
none            1.9G   76K  1.9G   1% /mnt/wslg/versions.txt
none            1.9G   76K  1.9G   1% /mnt/wslg/doc
C:\             119G  103G   16G  87% /mnt/c
D:\             517M   62M  456M  12% /mnt/d
E:\             239G  139G  100G  59% /mnt/e
G:\              15G  8.1G  7.0G  54% /mnt/g
tmpfs           388M     0  388M   0% /run/user/1000
# смотрим список всех смонтированных систем
mount
none on /mnt/wsl type tmpfs (rw,relatime)
none on /usr/lib/wsl/drivers type 9p (ro,nosuid,nodev,noatime,dirsync,aname=drivers;fmask=222;dmask=222,mmap,access=client,msize=65536,trans=fd,rfd=7,wfd=7)
/dev/sdc on / type ext4 (rw,relatime,discard,errors=remount-ro,data=ordered)
none on /mnt/wslg type tmpfs (rw,relatime)
/dev/sdc on /mnt/wslg/distro type ext4 (ro,relatime,discard,errors=remount-ro,data=ordered)
none on /usr/lib/wsl/lib type overlay (rw,nosuid,nodev,noatime,lowerdir=/gpu_lib_packaged:/gpu_lib_inbox,upperdir=/gpu_lib/rw/upper,workdir=/gpu_lib/rw/work)
rootfs on /init type rootfs (ro,size=1981624k,nr_inodes=495406)
none on /dev type devtmpfs (rw,nosuid,relatime,size=1981624k,nr_inodes=495406,mode=755)
sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,noatime)
proc on /proc type proc (rw,nosuid,nodev,noexec,noatime)
devpts on /dev/pts type devpts (rw,nosuid,noexec,noatime,gid=5,mode=620,ptmxmode=000)
none on /run type tmpfs (rw,nosuid,nodev,mode=755)
none on /run/lock type tmpfs (rw,nosuid,nodev,noexec,noatime)
none on /run/shm type tmpfs (rw,nosuid,nodev,noatime)
none on /dev/shm type tmpfs (rw,nosuid,nodev,noatime)
none on /run/user type tmpfs (rw,nosuid,nodev,noexec,noatime,mode=755)
binfmt_misc on /proc/sys/fs/binfmt_misc type binfmt_misc (rw,relatime)
tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755)
cgroup2 on /sys/fs/cgroup/unified type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate)
cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
cgroup on /sys/fs/cgroup/cpu type cgroup (rw,nosuid,nodev,noexec,relatime,cpu)
cgroup on /sys/fs/cgroup/cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct)
cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)
cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)
cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)
cgroup on /sys/fs/cgroup/net_cls type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls)
cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)
cgroup on /sys/fs/cgroup/net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio)
cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)
cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)
cgroup on /sys/fs/cgroup/rdma type cgroup (rw,nosuid,nodev,noexec,relatime,rdma)
cgroup on /sys/fs/cgroup/misc type cgroup (rw,nosuid,nodev,noexec,relatime,misc)
none on /mnt/wslg/versions.txt type overlay (rw,relatime,lowerdir=/systemvhd,upperdir=/system/rw/upper,workdir=/system/rw/work)
none on /mnt/wslg/doc type overlay (rw,relatime,lowerdir=/systemvhd,upperdir=/system/rw/upper,workdir=/system/rw/work)
none on /tmp/.X11-unix type tmpfs (ro,relatime)
C:\ on /mnt/c type 9p (rw,noatime,dirsync,aname=drvfs;path=C:\;uid=1000;gid=1000;symlinkroot=/mnt/,mmap,access=client,msize=65536,trans=fd,rfd=5,wfd=5)
D:\ on /mnt/d type 9p (rw,noatime,dirsync,aname=drvfs;path=D:\;uid=1000;gid=1000;symlinkroot=/mnt/,mmap,access=client,msize=65536,trans=fd,rfd=5,wfd=5)
E:\ on /mnt/e type 9p (rw,noatime,dirsync,aname=drvfs;path=E:\;uid=1000;gid=1000;symlinkroot=/mnt/,mmap,access=client,msize=65536,trans=fd,rfd=5,wfd=5)
G:\ on /mnt/g type 9p (rw,noatime,dirsync,aname=drvfs;path=G:\;uid=1000;gid=1000;symlinkroot=/mnt/,mmap,access=client,msize=65536,trans=fd,rfd=5,wfd=5)
none on /run/user type tmpfs (rw,relatime)
cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,name=systemd)
hugetlbfs on /dev/hugepages type hugetlbfs (rw,relatime,pagesize=2M)
mqueue on /dev/mqueue type mqueue (rw,relatime)
debugfs on /sys/kernel/debug type debugfs (rw,relatime)
fusectl on /sys/fs/fuse/connections type fusectl (rw,relatime)
tmpfs on /run/user/1000 type tmpfs (rw,nosuid,nodev,relatime,size=396984k,mode=700,uid=1000,gid=1000)
tmpfs on /mnt/wslg/run/user/1000 type tmpfs (rw,nosuid,nodev,relatime,size=396984k,mode=700,uid=1000,gid=1000)
none on /run/netns type tmpfs (rw,nosuid,nodev,mode=755)
nsfs on /run/netns/testns type nsfs (rw)
nsfs on /run/netns/testns type nsfs (rw)
# как видим система смонтирована в режиме чтения 'ro' (read only) tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,mode=755)
# перемонтриуем в режиме чтения/записи, создаем новую директорию и проверяем содержимое
mount -o remount,rw /sys/fs/cgroup
mkdir /sys/fs/cgroup/cpuset/testgroup1
ls /sys/fs/cgroup/cpuset/testgroup1
# если появились файлы в новой псевдодиректории, то все ок
# если видим папка пустая, псевдофайлы не создались, значит у нас версия механизма контроля групп cgroup2 'cgroup2 on /sys/fs/cgroup/unified type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate)'
# удаляем созданную папку и создаем ее в другой директории, после проверяем содержимое
rm -d /sys/fs/cgroup/cpuset/testgroup1
mkdir /sys/fs/cgroup/unified/tesgroup1
ls /sys/fs/cgroup/unified/tesgroup1/
cgroup.controllers  cgroup.freeze  cgroup.max.depth        cgroup.procs  cgroup.subtree_control  cgroup.type
cgroup.events       cgroup.kill    cgroup.max.descendants  cgroup.stat   cgroup.threads          cpu.stat
```
Как можно видеть, вместе с директорией сразу создался и набор файлов. Но не только! Создавая директорию по этому пути, мы создали и контрольную группу, которая тут же прошла инициализацию, создав набор файлов.

Помимо просто создания файлов (они же - псевдофайлы), они тут же заполняются информацией:
```bash
cat /sys/fs/cgroup/unified/tesgroup1/cpu.stat
usage_usec 0
user_usec 0
system_usec 0
# cat /sys/fs/cgroup/cpuset/testgroup1/cpu.pressure
# посмотрим текущий статус доступного процессора для текущего процесса
cat /proc/$$/status | grep 'allowed'
Cpus_allowed:   f
Cpus_allowed_list:      0-3
Mems_allowed:   1
Mems_allowed_list:      0
```
\$\$ в команде значит PID процесса, который выполняется нашей текущей командной оболочки.

Также в команде имеется grep - вывод строк, которые содержат сочетание символов, содержащееся в кавычках. Вывод уже интереснее - в нем мы видим уже известные нам параметры: cpus_allowed, mems_allowed.

Изменим количество доступной памяти в нашей новой контрольной группе
```bash
# Удаление пустой директории
rmdir -v /sys/fs/cgroup/unified/tesgroup1
vi /sys/fs/cgroup/unified/tesgroup1/memory.max
# 256M Esc + :wq
```

### Контейнеры и LXC
Из приведенного ранее примера должно быть примерно понятно для чего нужны контрольные группы: в них помещаются какие-либо процессы и над ними проводятся различные манипуляции - ограничение ресурсов, запрет на пользование ресурсами либо наоборот разрешение.

Давайте сделаем всю эту теорию более понятной! Разберем как именно используются cgroups в современных инструментах контейнеризации. Для этого предлагаю использовать LXC, так как он более прозрачно позволяет управлять разрешениями и запретами. С его помощью можно будет делать отсылки на теорию на любом шаге.

Прежде, чем мы запустим первый контейнер, сделаем небольшую отсылку к механизму работы LXC. Этот инструмент появился сравнительно недавно и имеет некоторые отличия от Docker. В каких случаях в целом удобно применять LXC?
1. Простота и наследственность: когда у нас уже есть какой-либо готовый сервис на выделенном сервере и этот сервис нужно правильно упаковать и передать разработчикам, тестировщикам либо в целом - другой команде. Да или даже просто - произвести перенос с 1 сервера на другой.
2. LXC очень похож на обычную виртуальную машину с точки зрения настройки, но потребляет ресурсов как обычный Docker. Это позволяет довольно легко настраивать сервисы LXC, так как они очень похожи на сервисы Linux.

Установка контейнера довольно простая:
```bash
# устанавливаем templates
sudo apt-get install lxc debootstrap bridge-utils lxc-templates
sudo lxc-create -n test123 -t ubuntu -f /usr/share/doc/lxc/examples/lxc-veth.conf
lxc-start -d -n test123
```